!!python/object/new:rex_gym.agents.tools.attr_dict.AttrDict
dictitems:
  algorithm: !!python/name:rex_gym.agents.ppo.algorithm.PPOAlgorithm ''
  discount: 0.985
  env: RexWalk-v0
  eval_episodes: 25
  init_logstd: -1
  init_mean_factor: 0.05
  kl_cutoff_coef: 1000
  kl_cutoff_factor: 2
  kl_init_penalty: 1
  kl_target: 0.01
  logdir: rex-test/20200707T172418-walk
  max_length: 1000
  network: !!python/name:rex_gym.agents.scripts.networks.ForwardGaussianPolicy ''
  num_agents: 25
  policy_layers: !!python/tuple
  - 200
  - 100
  policy_lr: 0.0001
  policy_optimizer: AdamOptimizer
  steps: 500000.0
  update_epochs_policy: 50
  update_epochs_value: 50
  update_every: 25
  use_gpu: false
  value_layers: !!python/tuple
  - 200
  - 100
  value_lr: 0.0003
  value_optimizer: AdamOptimizer
  weight_summaries:
    all: .*
    policy: .*/policy/.*
    value: .*/value/.*
state:
  _mutable: false
